{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/doductai/Youtube/dgl_tutorials/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source material\n",
    "https://docs.dgl.ai/tutorials/blitz/1_introduction.html#sphx-glr-tutorials-blitz-1-introduction-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Deep Graph Library (DGL)\n",
    "DGL integrates built-in functions which allow us to compute feature updates (for nodes and edges) based on the graph structure. \n",
    "\n",
    "To simutaneously update all node features, the following 3 functions are used:\n",
    "\n",
    "1. **message_func(edges)**: \n",
    "Each edge has attributres edge=[src, dst, data]. This function sends info $$src \\rightarrow dst$$ It stores everything needed to do node-feature update in a dict called \"mailbox\". This dict can be accessed via \"nodes.mailbox\"\n",
    "2. **reduce_func(nodes)**: Update the node feature by the update equation. All info in \"mailbox\" (obtained from message_func) will be used for the update.\n",
    "3. **g.update_all(message_func,reduce_func)**: send messages through all edges (by message_func) and update features of all nodes (by reduce_func)\n",
    "\n",
    "Additionally if the update equations involve edge updates, use **apply_edges(func)** to update edge features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cora dataset\n",
    "The cora dataset is single graph of citation network. It has\n",
    "1. Nodes = papers\n",
    "2. Edges = connectivity (citation) between the papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n",
      "Graph(num_nodes=2708, num_edges=10556,\n",
      "      ndata_schemes={'feat': Scheme(shape=(1433,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool), 'train_mask': Scheme(shape=(), dtype=torch.bool)}\n",
      "      edata_schemes={})\n"
     ]
    }
   ],
   "source": [
    "import dgl.data\n",
    "dataset=dgl.data.CoraGraphDataset()\n",
    "\n",
    "# extract the graph\n",
    "g=dataset[0]\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple case\n",
    "Assume we want to update node features by taking the mean of its neighbors\n",
    "$$h_i^{(l+1)}=\\text{mean}\\left(h_j^{(l)}: j\\in N(i)\\right)$$\n",
    "Note: $N(i)=$ all nodes j that send info to $i$, i.e. $(j,i)$ is an edge.\n",
    "1. message_func(self,edges): store the information $h_j^{(l)}$ of $j$ on each each $(j,i)$\n",
    "2. reduce_func(self,nodes): use the stored information to compute node update $\\text{mean}\\left(h_j^{(l)}: j\\in N(i)\\right)$.\n",
    "3. g.update_all(message_func,reduce_func)**: perform message_func and reduce_func simutaneously on all nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl.function as fn\n",
    "\n",
    "class mean_layer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def message_func(self,edges): # edge=[src,dst,data]\n",
    "        # extract src node features\n",
    "        m=edges.src['h']\n",
    "        return {'m': m} # stored in mailbox\n",
    "\n",
    "    def reduce_func(self,nodes):\n",
    "        # extract neigbor features from mailbox\n",
    "        m=nodes.mailbox['m']\n",
    "        return {'h_N': torch.mean(m,dim=1)}\n",
    "\n",
    "    def forward(self,g,h):\n",
    "        # h = input node features\n",
    "        with g.local_scope():\n",
    "            g.ndata['h']=h\n",
    "            g.update_all(self.message_func,self.reduce_func)\n",
    "            h_N=g.ndata['h_N']\n",
    "            return h_N\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Node 0 features before update -----\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "---- Node 0 features after update -----\n",
      "torch.Size([2708, 1433]) torch.Size([2708, 1433])\n",
      "tensor([0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0222, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "print(\"---- Node 0 features before update -----\")\n",
    "print(g.ndata['feat'][0])\n",
    "\n",
    "print(\"---- Node 0 features after update -----\")\n",
    "layer=mean_layer()\n",
    "h=g.ndata['feat']\n",
    "out=layer(g,h)\n",
    "print(g.ndata['feat'].shape, out.shape)\n",
    "print(out[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Graph Convolutional Network (GCN) from scratch\n",
    "In GCN, the update equation at each node is computed over its neighbors.\n",
    "$$h_i^{(l+1)}=W^{(l)}\\sum_{j\\in N(i)}\\dfrac{1}{c_{ji}}h_j^{(l)}+b^{(l)},$$\n",
    "where the terms are \n",
    "1. $N(i)=$ all neighbors of $i$ \n",
    "2. $c_{ji}=$ normalization constant $\\sqrt{\\text{deg}(j)}\\sqrt{\\text{deg}(i)}$\n",
    "3. $W$ (weight) and $b$ (bias) are parameters\n",
    "\n",
    "This GCN layer is available in dgl and can be called via **GraphConv(in_feats, out_feats)**. However, we will implement it from scratch by using message_func, reduce_func and update_all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) GraphConv layer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN_layer(nn.Module):\n",
    "    def __init__(self,in_dim,out_dim):\n",
    "        super().__init__()\n",
    "        self.linear=nn.Linear(in_dim,out_dim)\n",
    "\n",
    "        # initialize params by xavier\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self,module):\n",
    "        if isinstance(module,nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(module.weight)\n",
    "            torch.nn.init.zeros_(module.bias)\n",
    "\n",
    "    def forward(self,g,h):\n",
    "        # g = input graph, h=input node features\n",
    "        with g.local_scope():\n",
    "            \n",
    "            degrees=g.in_degrees().float()\n",
    "            norm=torch.pow(degrees,-0.5)\n",
    "            norm=norm.unsqueeze(-1)\n",
    "\n",
    "            # normalize all node features: h_i = h_i/sqrt(deg(i))\n",
    "            h=h*norm\n",
    "            # assign new node features\n",
    "            g.ndata['h']=h\n",
    "\n",
    "            # new feaurs for 'h' = sum of all neighbor features\n",
    "            #                 h_i=sum_j h_j/sqrt(deg(j))\n",
    "            g.update_all(message_func=fn.copy_u('h','m'), reduce_func=fn.sum('m','h'))\n",
    "\n",
    "            # normalize by deg(i)\n",
    "            out=g.ndata['h']*norm\n",
    "\n",
    "            # linear layer\n",
    "            out=self.linear(out)\n",
    "\n",
    "            return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "# input -> gcn1 -> relu -> gcn2 -> classification\n",
    "class GCN_model(nn.Module):\n",
    "    def __init__(self,in_dim,hidden_dim,num_classes):\n",
    "        super().__init__()\n",
    "        self.gcn1=GCN_layer(in_dim,hidden_dim)\n",
    "        self.gcn2=GCN_layer(hidden_dim,num_classes)\n",
    "    \n",
    "    def forward(self,g,features):\n",
    "        with g.local_scope():\n",
    "            h=self.gcn1(g,features)\n",
    "            h=F.relu(h)\n",
    "            h=self.gcn2(g,h)\n",
    "            return h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.184455 million parameters\n",
      "torch.Size([2708, 7])\n"
     ]
    }
   ],
   "source": [
    "in_dim=g.ndata['feat'].shape[-1]\n",
    "num_classes=dataset.num_classes\n",
    "\n",
    "hidden_dim=128\n",
    "\n",
    "net=GCN_model(in_dim, hidden_dim, num_classes)\n",
    "print(f\"{sum(p.numel() for p in net.parameters())/1e6} million parameters\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    features=g.ndata['feat']\n",
    "    out=net(g,features)\n",
    "    print(out.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_nodes: 140 | val_nodes: 500 | test_nodes: 1000\n"
     ]
    }
   ],
   "source": [
    "# train_mask, val_mask, test_mask\n",
    "train_mask=g.ndata['train_mask']\n",
    "val_mask=g.ndata['val_mask']\n",
    "test_mask=g.ndata['test_mask']\n",
    "\n",
    "print(f\"train_nodes: {sum(train_mask)} | val_nodes: {sum(val_mask)} | test_nodes: {sum(test_mask)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, graph,loss_fn,optimizer):\n",
    "    model.train()\n",
    "\n",
    "    features=graph.ndata['feat']\n",
    "    labels=graph.ndata['label']\n",
    "\n",
    "    # forward and backward\n",
    "    optimizer.zero_grad()\n",
    "    # prediction on the whole graph\n",
    "    logits=model(graph,features)\n",
    "    # only consider train_mask\n",
    "    loss=loss_fn(logits[train_mask], labels[train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # compute accuracy\n",
    "    preds=logits.argmax(dim=-1)\n",
    "    acc= (preds[train_mask]==labels[train_mask]).float().mean()\n",
    "\n",
    "    return loss, acc\n",
    "\n",
    "\n",
    "@torch.no_grad\n",
    "def evaluate(model,graph,loss_fn):\n",
    "    model.eval()\n",
    "    features=graph.ndata['feat']\n",
    "    labels=graph.ndata['label']\n",
    "\n",
    "    # forward\n",
    "    logits=model(graph,features)\n",
    "    loss=loss_fn(logits[val_mask],labels[val_mask])\n",
    "\n",
    "    # compute acc\n",
    "    preds=logits.argmax(dim=-1)\n",
    "    acc= (preds[val_mask]==labels[val_mask]).float().mean()\n",
    "\n",
    "    return loss,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.184455 million parameters\n",
      "Epoch: 0 | train_loss:  1.9456 | train_acc:  10.71% | val_loss:  1.8188 | val_acc:  46.20%\n",
      "Epoch: 1 | train_loss:  1.7384 | train_acc:  64.29% | val_loss:  1.7972 | val_acc:  22.40%\n",
      "Epoch: 2 | train_loss:  1.3862 | train_acc:  57.14% | val_loss:  1.2557 | val_acc:  73.40%\n",
      "Epoch: 3 | train_loss:  0.9328 | train_acc:  86.43% | val_loss:  1.1686 | val_acc:  67.00%\n",
      "Epoch: 4 | train_loss:  0.5854 | train_acc:  90.00% | val_loss:  0.9531 | val_acc:  74.20%\n",
      "Epoch: 5 | train_loss:  0.2967 | train_acc:  97.14% | val_loss:  0.8331 | val_acc:  75.20%\n",
      "Epoch: 6 | train_loss:  0.1710 | train_acc:  98.57% | val_loss:  0.8206 | val_acc:  72.20%\n",
      "Epoch: 7 | train_loss:  0.1195 | train_acc:  98.57% | val_loss:  0.7423 | val_acc:  77.60%\n",
      "Epoch: 8 | train_loss:  0.0515 | train_acc:  100.00% | val_loss:  0.7458 | val_acc:  78.60%\n",
      "Epoch: 9 | train_loss:  0.0248 | train_acc:  100.00% | val_loss:  0.8103 | val_acc:  76.80%\n",
      "Epoch: 10 | train_loss:  0.0150 | train_acc:  100.00% | val_loss:  0.8962 | val_acc:  76.80%\n",
      "Epoch: 11 | train_loss:  0.0105 | train_acc:  100.00% | val_loss:  0.9755 | val_acc:  76.60%\n",
      "Epoch: 12 | train_loss:  0.0079 | train_acc:  100.00% | val_loss:  1.0311 | val_acc:  76.60%\n",
      "Epoch: 13 | train_loss:  0.0046 | train_acc:  100.00% | val_loss:  1.0726 | val_acc:  76.80%\n",
      "Epoch: 14 | train_loss:  0.0022 | train_acc:  100.00% | val_loss:  1.1120 | val_acc:  77.40%\n",
      "Epoch: 15 | train_loss:  0.0011 | train_acc:  100.00% | val_loss:  1.1522 | val_acc:  77.80%\n",
      "Epoch: 16 | train_loss:  0.0006 | train_acc:  100.00% | val_loss:  1.1935 | val_acc:  78.80%\n",
      "Epoch: 17 | train_loss:  0.0004 | train_acc:  100.00% | val_loss:  1.2355 | val_acc:  78.40%\n",
      "Epoch: 18 | train_loss:  0.0003 | train_acc:  100.00% | val_loss:  1.2780 | val_acc:  78.20%\n",
      "Epoch: 19 | train_loss:  0.0002 | train_acc:  100.00% | val_loss:  1.3201 | val_acc:  78.40%\n",
      "Epoch: 20 | train_loss:  0.0001 | train_acc:  100.00% | val_loss:  1.3613 | val_acc:  78.00%\n",
      "Epoch: 21 | train_loss:  0.0001 | train_acc:  100.00% | val_loss:  1.4015 | val_acc:  78.00%\n",
      "Epoch: 22 | train_loss:  0.0001 | train_acc:  100.00% | val_loss:  1.4402 | val_acc:  78.00%\n",
      "Epoch: 23 | train_loss:  0.0001 | train_acc:  100.00% | val_loss:  1.4774 | val_acc:  78.00%\n",
      "Epoch: 24 | train_loss:  0.0001 | train_acc:  100.00% | val_loss:  1.5129 | val_acc:  77.80%\n",
      "Epoch: 25 | train_loss:  0.0000 | train_acc:  100.00% | val_loss:  1.5466 | val_acc:  77.60%\n",
      "Epoch: 26 | train_loss:  0.0000 | train_acc:  100.00% | val_loss:  1.5786 | val_acc:  77.60%\n",
      "Epoch: 27 | train_loss:  0.0000 | train_acc:  100.00% | val_loss:  1.6087 | val_acc:  77.40%\n",
      "Epoch: 28 | train_loss:  0.0000 | train_acc:  100.00% | val_loss:  1.6368 | val_acc:  77.40%\n",
      "Epoch: 29 | train_loss:  0.0000 | train_acc:  100.00% | val_loss:  1.6630 | val_acc:  77.40%\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1442)\n",
    "\n",
    "num_epochs=30\n",
    "\n",
    "model=GCN_model(in_dim,hidden_dim,num_classes)\n",
    "print(f\"{sum(p.numel() for p in model.parameters())/1e6} million parameters\")\n",
    "\n",
    "loss_fn=F.cross_entropy\n",
    "optimizer=torch.optim.AdamW(model.parameters(),lr=0.1)\n",
    "\n",
    "# train and test\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc=train(model,g,loss_fn,optimizer)\n",
    "    val_loss, val_acc=evaluate(model,g,loss_fn)\n",
    "    print(f\"Epoch: {epoch} | train_loss: {train_loss: .4f} | train_acc: {train_acc*100: .2f}% | val_loss: {val_loss: .4f} | val_acc: {val_acc*100: .2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. GCN with dgl.nn.pytorch.conv.GraphConv\n",
    "dgl.nn.pytorch.conv.GraphConv(in_feats, out_feats, norm='both', weight=True, bias=True, activation=None, allow_zero_in_degree=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import GraphConv\n",
    "\n",
    "# model: input -> gcn1 -> relu -> gcn2 -> classification\n",
    "class GCN_Net(nn.Module):\n",
    "    def __init__(self,in_dim,hidden_dim,num_classes):\n",
    "        super().__init__()\n",
    "        self.gcn1=GraphConv(in_dim,hidden_dim)\n",
    "        self.gcn2=GraphConv(hidden_dim,num_classes)\n",
    "\n",
    "    def forward(self,g, features):\n",
    "        h=self.gcn1(g,features)\n",
    "        h=F.relu(h)\n",
    "        h=self.gcn2(g,h)\n",
    "        return h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.184455 million parameters\n",
      "Epoch: 0 | train_loss:  1.9451 | train_acc:  17.14% | val_loss:  1.9049 | val_acc:  34.00%\n",
      "Epoch: 1 | train_loss:  1.7513 | train_acc:  57.14% | val_loss:  1.6535 | val_acc:  45.40%\n",
      "Epoch: 2 | train_loss:  1.4345 | train_acc:  61.43% | val_loss:  1.4392 | val_acc:  60.40%\n",
      "Epoch: 3 | train_loss:  0.9092 | train_acc:  92.14% | val_loss:  1.2300 | val_acc:  59.80%\n",
      "Epoch: 4 | train_loss:  0.5409 | train_acc:  92.86% | val_loss:  0.8813 | val_acc:  78.80%\n",
      "Epoch: 5 | train_loss:  0.2485 | train_acc:  97.14% | val_loss:  0.7233 | val_acc:  77.40%\n",
      "Epoch: 6 | train_loss:  0.1545 | train_acc:  97.86% | val_loss:  0.6567 | val_acc:  81.20%\n",
      "Epoch: 7 | train_loss:  0.0649 | train_acc:  99.29% | val_loss:  0.7653 | val_acc:  77.40%\n",
      "Epoch: 8 | train_loss:  0.0383 | train_acc:  100.00% | val_loss:  0.8597 | val_acc:  75.00%\n",
      "Epoch: 9 | train_loss:  0.0273 | train_acc:  100.00% | val_loss:  0.8131 | val_acc:  79.20%\n",
      "Epoch: 10 | train_loss:  0.0102 | train_acc:  100.00% | val_loss:  0.8039 | val_acc:  79.20%\n",
      "Epoch: 11 | train_loss:  0.0054 | train_acc:  100.00% | val_loss:  0.8392 | val_acc:  81.20%\n",
      "Epoch: 12 | train_loss:  0.0047 | train_acc:  100.00% | val_loss:  0.8939 | val_acc:  80.80%\n",
      "Epoch: 13 | train_loss:  0.0045 | train_acc:  100.00% | val_loss:  0.9511 | val_acc:  80.60%\n",
      "Epoch: 14 | train_loss:  0.0033 | train_acc:  100.00% | val_loss:  1.0078 | val_acc:  80.40%\n",
      "Epoch: 15 | train_loss:  0.0018 | train_acc:  100.00% | val_loss:  1.0669 | val_acc:  80.00%\n",
      "Epoch: 16 | train_loss:  0.0009 | train_acc:  100.00% | val_loss:  1.1288 | val_acc:  79.80%\n",
      "Epoch: 17 | train_loss:  0.0004 | train_acc:  100.00% | val_loss:  1.1921 | val_acc:  79.00%\n",
      "Epoch: 18 | train_loss:  0.0002 | train_acc:  100.00% | val_loss:  1.2554 | val_acc:  77.60%\n",
      "Epoch: 19 | train_loss:  0.0001 | train_acc:  100.00% | val_loss:  1.3174 | val_acc:  78.20%\n",
      "Epoch: 20 | train_loss:  0.0001 | train_acc:  100.00% | val_loss:  1.3772 | val_acc:  78.00%\n",
      "Epoch: 21 | train_loss:  0.0000 | train_acc:  100.00% | val_loss:  1.4341 | val_acc:  77.80%\n",
      "Epoch: 22 | train_loss:  0.0000 | train_acc:  100.00% | val_loss:  1.4879 | val_acc:  77.60%\n",
      "Epoch: 23 | train_loss:  0.0000 | train_acc:  100.00% | val_loss:  1.5384 | val_acc:  77.40%\n",
      "Epoch: 24 | train_loss:  0.0000 | train_acc:  100.00% | val_loss:  1.5855 | val_acc:  77.20%\n",
      "Epoch: 25 | train_loss:  0.0000 | train_acc:  100.00% | val_loss:  1.6291 | val_acc:  77.20%\n",
      "Epoch: 26 | train_loss:  0.0000 | train_acc:  100.00% | val_loss:  1.6692 | val_acc:  77.20%\n",
      "Epoch: 27 | train_loss:  0.0000 | train_acc:  100.00% | val_loss:  1.7058 | val_acc:  76.80%\n",
      "Epoch: 28 | train_loss:  0.0000 | train_acc:  100.00% | val_loss:  1.7390 | val_acc:  76.80%\n",
      "Epoch: 29 | train_loss:  0.0000 | train_acc:  100.00% | val_loss:  1.7688 | val_acc:  76.80%\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model2=GCN_Net(in_dim,hidden_dim,num_classes)\n",
    "print(f\"{sum(p.numel() for p in model2.parameters())/1e6} million parameters\")\n",
    "\n",
    "loss_fn=F.cross_entropy\n",
    "optimizer=torch.optim.AdamW(model2.parameters(), lr=0.1)\n",
    "\n",
    "# train and test\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc=train(model2,g,loss_fn,optimizer)\n",
    "    val_loss, val_acc=evaluate(model2,g,loss_fn)\n",
    "    print(f\"Epoch: {epoch} | train_loss: {train_loss: .4f} | train_acc: {train_acc*100: .2f}% | val_loss: {val_loss: .4f} | val_acc: {val_acc*100: .2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
